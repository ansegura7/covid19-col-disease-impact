{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Tuberculosis\n",
    "- **Project: Analysis of the dynamics of COVID-19 infection in Colombia**\n",
    "- **Analysis: Time Series**\n",
    "- **Data: SIVIGILA - TB rate by epidemiological period in Colombia [2017-2020]**\n",
    "- **Created by: Andrés Segura Tinoco**\n",
    "- **Created on: August 1, 2020**\n",
    "- **Updated on: August 11, 2020**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import timeit\n",
    "from scipy import stats\n",
    "from math import pi, sqrt, ceil, log\n",
    "from warnings import catch_warnings\n",
    "from warnings import filterwarnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Parallel libraries\n",
    "from multiprocessing import cpu_count\n",
    "from joblib import Parallel\n",
    "from joblib import delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Time Series libraries\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Plot libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index\n",
    "1. Visual Analytics\n",
    "2. Base Line\n",
    "3. Time Series Analysis\n",
    "4. Box-Jenkins Analysis\n",
    "5. Holt-Winters Analysis\n",
    "6. Compare Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>period</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2017-01-08</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2017-01-15</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2017-01-22</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2017-01-29</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>2020-03-15</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>2020-03-22</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>2020-03-29</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>2020-04-05</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>2020-04-12</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  year  month  week  period  value\n",
       "52  2017-01-01  2017      1     1       1    298\n",
       "53  2017-01-08  2017      1     2       1    256\n",
       "54  2017-01-15  2017      1     3       1    347\n",
       "55  2017-01-22  2017      1     4       1    289\n",
       "56  2017-01-29  2017      1     5       2    312\n",
       "..         ...   ...    ...   ...     ...    ...\n",
       "219 2020-03-15  2020      3    12       3    264\n",
       "220 2020-03-22  2020      3    13       4    186\n",
       "221 2020-03-29  2020      3    14       4    178\n",
       "222 2020-04-05  2020      4    15       4    121\n",
       "223 2020-04-12  2020      4    16       4    115\n",
       "\n",
       "[172 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read raw data\n",
    "data_url = '../data/tb_weekly_data.csv'\n",
    "rawdata = pd.read_csv(data_url, parse_dates=['date'])\n",
    "rawdata = rawdata[rawdata['date'] >= '2017-01-01']\n",
    "rawdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>period</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-29</th>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>1188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-02-26</th>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>1209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-26</th>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>1184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-23</th>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>1151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-21</th>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>1190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-18</th>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>1105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-16</th>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>1101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-13</th>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>1151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-10</th>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>1172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-08</th>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>1158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-05</th>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>1119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-03</th>\n",
       "      <td>2017</td>\n",
       "      <td>13</td>\n",
       "      <td>982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31</th>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-28</th>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>1191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-25</th>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>1290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-25</th>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>1112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-22</th>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>1178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-20</th>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>1129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-17</th>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>1085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-15</th>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>1130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-12</th>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>1156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-09</th>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>1183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-07</th>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>1111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-04</th>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>1128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-02</th>\n",
       "      <td>2018</td>\n",
       "      <td>13</td>\n",
       "      <td>991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-30</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-27</th>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>1215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-24</th>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>1223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-24</th>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>1054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-21</th>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>1176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-19</th>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>1184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-16</th>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>1099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-14</th>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>1221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-11</th>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>1209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-08</th>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>1208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-06</th>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>1158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-03</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>1116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-01</th>\n",
       "      <td>2019</td>\n",
       "      <td>13</td>\n",
       "      <td>797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-29</th>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-26</th>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>1201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-23</th>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>1118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-22</th>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            year  period  value\n",
       "date                           \n",
       "2017-01-01  2017       1   1190\n",
       "2017-01-29  2017       2   1188\n",
       "2017-02-26  2017       3   1209\n",
       "2017-03-26  2017       4   1184\n",
       "2017-04-23  2017       5   1151\n",
       "2017-05-21  2017       6   1190\n",
       "2017-06-18  2017       7   1105\n",
       "2017-07-16  2017       8   1101\n",
       "2017-08-13  2017       9   1151\n",
       "2017-09-10  2017      10   1172\n",
       "2017-10-08  2017      11   1158\n",
       "2017-11-05  2017      12   1119\n",
       "2017-12-03  2017      13    982\n",
       "2017-12-31  2018       1   1143\n",
       "2018-01-28  2018       2   1191\n",
       "2018-02-25  2018       3   1290\n",
       "2018-03-25  2018       4   1112\n",
       "2018-04-22  2018       5   1178\n",
       "2018-05-20  2018       6   1129\n",
       "2018-06-17  2018       7   1085\n",
       "2018-07-15  2018       8   1130\n",
       "2018-08-12  2018       9   1156\n",
       "2018-09-09  2018      10   1183\n",
       "2018-10-07  2018      11   1111\n",
       "2018-11-04  2018      12   1128\n",
       "2018-12-02  2018      13    991\n",
       "2018-12-30  2019       1   1128\n",
       "2019-01-27  2019       2   1215\n",
       "2019-02-24  2019       3   1223\n",
       "2019-03-24  2019       4   1054\n",
       "2019-04-21  2019       5   1176\n",
       "2019-05-19  2019       6   1184\n",
       "2019-06-16  2019       7   1099\n",
       "2019-07-14  2019       8   1221\n",
       "2019-08-11  2019       9   1209\n",
       "2019-09-08  2019      10   1208\n",
       "2019-10-06  2019      11   1158\n",
       "2019-11-03  2019      12   1116\n",
       "2019-12-01  2019      13    797\n",
       "2019-12-29  2020       1   1101\n",
       "2020-01-26  2020       2   1201\n",
       "2020-02-23  2020       3   1118\n",
       "2020-03-22  2020       4    600"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grouping by epidemiological period\n",
    "dataset = rawdata.groupby(['year', 'period']).agg('sum')\n",
    "dataset = dataset.drop(columns=['month', 'week'])\n",
    "\n",
    "for ix, row in dataset.iterrows():\n",
    "    curr_date = min(rawdata[(rawdata['year'] == ix[0]) & (rawdata['period'] == ix[1])]['date'])\n",
    "    dataset.at[ix, 'date'] = pd.to_datetime(curr_date).date()\n",
    "\n",
    "dataset.reset_index(inplace=True)\n",
    "dataset = dataset.reindex(columns=['date', 'year', 'period', 'value'])\n",
    "dataset = dataset.set_index('date')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Visual Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Plot full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pretty x axis labels\n",
    "def get_x_labels(all_labels):\n",
    "    x_labels = []\n",
    "    for ix in range(len(all_labels)):\n",
    "        if ix % 5 == 0:\n",
    "            date_label = str(all_labels[ix]).replace('T', '*').split('*')[0]\n",
    "            x_labels.append(date_label)\n",
    "        else:\n",
    "            x_labels.append('')\n",
    "    return x_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cooking weekly data\n",
    "x_date = np.array(dataset.index)\n",
    "x_data = np.array(range(len(x_date))).reshape((-1, 1))\n",
    "y_data = np.array(dataset.value)\n",
    "xticks = get_x_labels(x_date)\n",
    "max_y = int(max(y_data) * 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot raw data\n",
    "plt.figure(figsize=(18, 7), dpi=200)\n",
    "plt.plot(x_data, y_data, label='TB data')\n",
    "plt.ylim((0, max_y))\n",
    "x_anno = {'2018':13, '2019':26, '2020':39}\n",
    "for k, v in x_anno.items():\n",
    "    plt.axvline(x=v, color='k', linestyle='--', alpha=.8)\n",
    "    plt.text(x=v+0.2, y=50, s=k, rotation='vertical')\n",
    "plt.title('Tuberculosis by Period in Colombia', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=10)\n",
    "plt.ylabel('Num. Deaths', fontsize=10)\n",
    "plt.xticks(x_data, xticks, rotation=45)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Data by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping data by year\n",
    "dt = dataset.groupby(['year']).agg('sum')\n",
    "dt['diff'] = dt['value'].diff()\n",
    "dt[['value', 'diff']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping data by January and February\n",
    "dt = dataset[dataset['period'].isin([1, 2, 3, 4])].groupby(['year']).agg('sum')\n",
    "dt['diff'] = dt['value'].diff()\n",
    "dt[['value', 'diff']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cooking data for year 2017\n",
    "data_2017 = dataset[dataset['year'] == 2017]['value']\n",
    "print('2017 Records: %s' % len(data_2017))\n",
    "print('Total cases: %s' % sum(data_2017))\n",
    "print('Average cases: %.2f' % np.mean(data_2017))\n",
    "print('Median cases: %.2f' % np.median(data_2017))\n",
    "print('Standard deviation: %.2f' % np.std(data_2017))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cooking data for year 2018\n",
    "data_2018 = dataset[dataset['year'] == 2018]['value']\n",
    "print('2018 Records: %s' % len(data_2018))\n",
    "print('Total cases: %s' % sum(data_2018))\n",
    "print('Average cases: %.2f' % np.mean(data_2018))\n",
    "print('Median cases: %.2f' % np.median(data_2018))\n",
    "print('Standard deviation: %.2f' % np.std(data_2018))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cooking data for year 2019\n",
    "data_2019 = dataset[dataset['year'] == 2019]['value']\n",
    "print('2019 Records: %s' % len(data_2019))\n",
    "print('Total cases: %s' % sum(data_2019))\n",
    "print('Average cases: %.2f' % np.mean(data_2019))\n",
    "print('Median cases: %.2f' % np.median(data_2019))\n",
    "print('Standard deviation: %.2f' % np.std(data_2019))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cooking data for year 2020\n",
    "data_2020 = dataset[dataset['year'] == 2020]['value']\n",
    "print('2020 Records: %s' % len(data_2020))\n",
    "print('Total cases: %s' % sum(data_2020))\n",
    "print('Average cases: %.2f' % np.mean(data_2020))\n",
    "print('Median cases: %.2f' % np.median(data_2020))\n",
    "print('Standard deviation: %.2f' % np.std(data_2020))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot trends by year\n",
    "plt.figure(figsize=(18, 7), dpi=200)\n",
    "plt.plot(range(len(data_2017)), data_2017, label='2017')\n",
    "plt.plot(range(len(data_2018)), data_2018, label='2018')\n",
    "plt.plot(range(len(data_2019)), data_2019, label='2019')\n",
    "plt.plot(range(len(data_2020)), data_2020, label='2020')\n",
    "plt.ylim((0, max_y))\n",
    "plt.title('Annual TB trends', fontsize=16)\n",
    "plt.xlabel('Week', fontsize=10)\n",
    "plt.ylabel('Num. Deaths', fontsize=10)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Check Month-wise (seasonal) and Year-wise (trend) distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8), dpi= 200)\n",
    "sns.boxplot(x='year', y='value', data=dataset, ax=axes[0])\n",
    "sns.boxplot(x='period', y='value', data=dataset, ax=axes[1])\n",
    "\n",
    "# Set Title\n",
    "axes[0].set_title('Year-wise Box Plot\\n(The Trend)', fontsize=16); \n",
    "axes[1].set_title('Month-wise Box Plot\\n(The Seasonality)', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result\n",
    "The dataset contains an obvious trend but no obvious seasonal component."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Base Line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error validation functions are defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate root mean squared error or RMSE\n",
    "def calc_rmse(actual, predicted):\n",
    "    return sqrt(mean_squared_error(actual, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean absolute percentage error or MAPE\n",
    "def percentage_error(actual, predicted):\n",
    "    res = np.empty(actual.shape)\n",
    "    for j in range(actual.shape[0]):\n",
    "        if actual[j] != 0:\n",
    "            res[j] = (actual[j] - predicted[j]) / actual[j]\n",
    "        else:\n",
    "            res[j] = predicted[j] / np.mean(actual)\n",
    "    return res\n",
    "\n",
    "def calc_mape(y_true, y_pred): \n",
    "    return np.mean(np.abs(percentage_error(np.asarray(y_true), np.asarray(y_pred)))) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate confidence interval\n",
    "def get_interval(y, y_pred, pi=0.99):\n",
    "    n = len(y)\n",
    "    \n",
    "    # Get standard deviation of y_test\n",
    "    sum_errs = np.sum((y - y_pred)**2) / (n - 2)\n",
    "    stdev = np.sqrt(sum_errs)\n",
    "    \n",
    "    # Get interval from standard deviation\n",
    "    one_minus_pi = 1 - pi\n",
    "    ppf_lookup = 1 - (one_minus_pi / 2)\n",
    "    z_score = stats.norm.ppf(ppf_lookup)\n",
    "    interval = z_score * stdev\n",
    "    \n",
    "    return interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate AIC for regression\n",
    "def calc_aic(actual, predicted, k=1):\n",
    "    n = len(actual)\n",
    "    mse = mean_squared_error(actual, predicted)\n",
    "    aic = n * log(mse) + 2 * k\n",
    "    return aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate BIC for regression\n",
    "def calc_bic(actual, predicted, k=1):\n",
    "    n = len(actual)\n",
    "    mse = mean_squared_error(actual, predicted)\n",
    "    bic = n * log(mse) + k * log(n)\n",
    "    return bic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model LR\n",
    "degree = 3\n",
    "x_ = PolynomialFeatures(degree=degree, include_bias=True).fit_transform(x_data)\n",
    "model = LinearRegression().fit(x_, y_data)\n",
    "\n",
    "# Validate model\n",
    "r_sq = model.score(x_, y_data)\n",
    "print('Correlation:', sqrt(r_sq))\n",
    "print('Coefficient of determination:', r_sq)\n",
    "print('Intercept:', model.intercept_, ', Slope:', model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "y_pred = model.predict(x_)\n",
    "k = len(model.coef_) + 1\n",
    "\n",
    "# Calculate errors\n",
    "rmse = calc_rmse(y_data, y_pred)\n",
    "mape = calc_mape(y_data, y_pred)\n",
    "aic = calc_aic(y_data, y_pred, k)\n",
    "bic = calc_bic(y_data, y_pred, k)\n",
    "print('Number of parameters: %d' % (k))\n",
    "print('The RMSE of our forecasts is: {}'.format(round(rmse, 3)))\n",
    "print('The MAPE of our forecasts is: {} %'.format(round(mape, 3)))\n",
    "print('The AIC of our forecasts is: {}'.format(round(aic, 3)))\n",
    "print('The BIC of our forecasts is: {}'.format(round(bic, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_alpha = 0.9\n",
    "ci = get_interval(y_data, y_pred, ci_alpha)\n",
    "print('Conf. Int.:', ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "periods = 52\n",
    "x_date2 = pd.date_range(start='2017-01-01', end='2020-12-27', periods=periods)\n",
    "x_ = PolynomialFeatures(degree=degree, include_bias=True).fit_transform(np.array(range(13 * 4)).reshape((-1, 1)))\n",
    "y_pred = model.predict(x_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot chart\n",
    "plt.figure(figsize=(18, 7), dpi=200)\n",
    "plt.plot(x_date, y_data, '-', label='TB data')\n",
    "plt.plot(x_date2, y_pred, '-', color='green', label='Trend', linestyle='dashed')\n",
    "plt.fill_between(x_date2, y_pred - ci, y_pred + ci, color='k', alpha=.25)\n",
    "plt.ylim((0, max_y))\n",
    "plt.title('TB in Colombia with Trends', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=10)\n",
    "plt.ylabel('Num. Deaths', fontsize=10)\n",
    "plt.xticks(fontsize=10, rotation=45)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result\n",
    "- RMSE: 96.32\n",
    "- MAPE: 6.723 %\n",
    "- AIC: 402.82\n",
    "- BIC: 411.626"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control param for SARIMA and Holt-Winters methods\n",
    "perc_test = 0.20 # 20%\n",
    "data_freq = 13\n",
    "n_forecast = 13\n",
    "run_fit = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cooking time-series data with frequency\n",
    "filter_date = pd.to_datetime('2020-01-01').date()\n",
    "series_data = dataset['value']\n",
    "series_data = series_data.loc[series_data.index < filter_date]\n",
    "series_data = series_data.asfreq(freq='4W')\n",
    "series_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Statistical tests for stationarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a stationary **time series**, statistical properties such as mean and variance are constant over time. In a non-stationary series, these properties are dependent on time.\n",
    "\n",
    "Augmented Dickey-Fuller unit root test:\n",
    "- Tests for trend non-stationarity.\n",
    "- Null hypothesis ($H_0$) is time series is non-stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf_results = adfuller(series_data)\n",
    "print('ADF Statistic:', adf_results[0])\n",
    "print('p-value:', adf_results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf_results = adfuller(series_data.diff().dropna())\n",
    "print('ADF Statistic:', adf_results[0])\n",
    "print('p-value:', adf_results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result\n",
    "- Based on ADF test statistic and p-value the time series is non-stationary. We fail to reject the null hypothesis.\n",
    "- However, the first difference in the time series itself is stationary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Correlation and autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 8))\n",
    "plot_acf(series_data, lags=20, ax=ax1)\n",
    "plot_pacf(series_data, lags=20, ax=ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result\n",
    "We can use a $p = 3$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Check seasonal decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These components are defined as follows:\n",
    "- Level: The average value in the series.\n",
    "- Trend: The increasing or decreasing value in the series.\n",
    "- Seasonality: The repeating short-term cycle in the series.\n",
    "- Noise: The random variation in the series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1. Additive decomposition\n",
    "Additive series = Level + Trend + Seasonality + Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additive Decomposition\n",
    "# result_add = seasonal_decompose(series_data, model='additive', extrapolate_trend='freq')\n",
    "\n",
    "# Show Additive Decompose\n",
    "# plt.rcParams.update({'figure.figsize': (12, 10)})\n",
    "# result_add.plot()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2. Multiplicative decomposition\n",
    "Multiplicative series = Level x Trend x Seasonality x Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiplicative Decomposition\n",
    "# result_add = seasonal_decompose(series_data, model='multiplicative', extrapolate_trend='freq')\n",
    "\n",
    "# Show Additive Decompose\n",
    "# plt.rcParams.update({'figure.figsize': (12, 10)})\n",
    "# result_add.plot()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result\n",
    "Both the additive and multiplicative models have the following properties:\n",
    "- Clear decreasing trend.\n",
    "- It's a seasonal time series.\n",
    "- The residuals oscillate around 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Box-Jenkins Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In time series analysis, the Box–Jenkins method, applies autoregressive moving average (ARMA) or autoregressive integrated moving average (ARIMA) models to find the best fit of a time-series model to past values of a time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Select best parameters for SARIMA model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AIC - Akaike information criterion\n",
    "- Lower AIC indicates a better model\n",
    "- AIC likes to choose simple models with lower order\n",
    "\n",
    "BIC - Bayesian information criterion\n",
    "- Very similar to AIC\n",
    "- Lower BIC indicates a better model\n",
    "- BIC likes to choose simple models with lower order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of SARIMA configs to try\n",
    "def arima_smoothing_configs():\n",
    "    \n",
    "    # Define the p, d and q parameters to take any value between 0 and 2\n",
    "    p = d = q = range(0, 3)\n",
    "\n",
    "    # Generate all different combinations of p, q and q triplets\n",
    "    pdq = list(itertools.product(p, d, q))\n",
    "\n",
    "    # Generate all different combinations of seasonal p, q and q triplets\n",
    "    seasonal_pdq  = [(x[0], x[1], x[2], data_freq) for x in list(itertools.product(p, d, q))]\n",
    "    \n",
    "    return pdq, seasonal_pdq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Parameter Selection for the ARIMA Time Series Model\n",
    "def arima_grid_search(pdq, seasonal_pdq):\n",
    "    start_time = timeit.default_timer()\n",
    "    \n",
    "    # Specify to ignore warning messages\n",
    "    filterwarnings(\"ignore\")\n",
    "    \n",
    "    for param in pdq:\n",
    "        for param_seasonal in seasonal_pdq:\n",
    "            try:\n",
    "                mod = sm.tsa.statespace.SARIMAX(series_data,\n",
    "                                                order=param,\n",
    "                                                seasonal_order=param_seasonal,\n",
    "                                                enforce_stationarity=False,\n",
    "                                                enforce_invertibility=False)\n",
    "                results = mod.fit()\n",
    "                \n",
    "                if results.aic > 0 or results.bic > 0:\n",
    "                    print('SARIMA: {} x {}, AIC:{}, BIC:{}'.format(param, param_seasonal, results.aic, results.bic))\n",
    "            except:\n",
    "                # Print AIC and BIC as None when fails\n",
    "                print('Error: SARIMA: {} x {}, AIC:{}, BIC:{}'.format(param, param_seasonal, None, None))\n",
    "    \n",
    "    # Elapsed time\n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    print('Elapsed time', elapsed, 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run ARIMA fit\n",
    "if run_fit:\n",
    "    \n",
    "    # Calculation params\n",
    "    pdq, seasonal_pdq = arima_smoothing_configs()\n",
    "    \n",
    "    # Run grid search\n",
    "    arima_grid_search(pdq, seasonal_pdq)\n",
    "    print('Done SARIMA method')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Create SARIMA model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prob(Q) - p-value for null hypothesis that residuals are uncorrelated\n",
    "- Prob(JB) - p-value for null hypothesis that residuals are normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting a SARIMA Time Series model\n",
    "filterwarnings(\"ignore\")\n",
    "model = sm.tsa.statespace.SARIMAX(series_data, order=(2, 2, 2), seasonal_order=(2, 0, 2, data_freq), \n",
    "                                  enforce_stationarity=False, enforce_invertibility=False)\n",
    "model = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot diagnostics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the model fits well the residuals will be white Gaussian noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.plot_diagnostics(figsize=(16, 12))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Validating SARIMA forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start prediction from...\n",
    "ix_test = ceil(len(series_data) * (1 - perc_test))\n",
    "start_date = series_data.index[ix_test]\n",
    "ix_test, start_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.1. Validate prediction with dynamic False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate prediction with dynamic False\n",
    "pred = model.get_prediction(start=start_date, dynamic=False)\n",
    "pred_ci = pred.conf_int(alpha=1-ci_alpha)\n",
    "\n",
    "# Show predictions\n",
    "y_forecasted = pd.Series(np.array([round(p) for p in pred.predicted_mean]), pred.predicted_mean.index)\n",
    "y_forecasted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plt.figure(figsize=(18, 7), dpi=200)\n",
    "ax = series_data.plot(label='Observed')\n",
    "y_forecasted.plot(ax=ax, label='Forecast', color='green', linestyle='dashed')\n",
    "ax.fill_between(pred_ci.index, pred_ci.iloc[:, 0], pred_ci.iloc[:, 1], color='k', alpha=.2)\n",
    "plt.ylim((0, max_y))\n",
    "plt.title('TB with One-step ahead Forecast', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=10)\n",
    "plt.ylabel('Num. Deaths', fontsize=10)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the predicted and true values of our time series\n",
    "y_truth = series_data[start_date:]\n",
    "\n",
    "# Compute the errors\n",
    "rmse = calc_rmse(y_truth, y_forecasted)\n",
    "mape = calc_mape(y_truth, y_forecasted)\n",
    "print('The RMSE of our forecasts is: {}'.format(round(rmse, 3)))\n",
    "print('The MAPE of our forecasts is: {} %'.format(round(mape, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.2. Validate prediction with dynamic True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "pred_dynamic = model.get_prediction(start=start_date, dynamic=True, full_results=True)\n",
    "pred_dynamic_ci = pred_dynamic.conf_int(alpha=1-ci_alpha)\n",
    "\n",
    "# Show predictions\n",
    "y_forecasted = pd.Series(np.array([round(p) for p in pred_dynamic.predicted_mean]), pred_dynamic.predicted_mean.index)\n",
    "y_forecasted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plt.figure(figsize=(18, 7), dpi=200)\n",
    "ax = series_data.plot(label='Observed')\n",
    "y_forecasted.plot(ax=ax, label='Forecast', color='green', linestyle='dashed')\n",
    "ax.fill_betweenx(ax.get_ylim(), pred_dynamic_ci.index[0], pred_dynamic_ci.index[-1], alpha=.2, zorder=-1)\n",
    "ax.fill_between(pred_dynamic_ci.index, pred_dynamic_ci.iloc[:, 0], pred_dynamic_ci.iloc[:, 1], color='k', alpha=.2)\n",
    "plt.ylim((0, max_y))\n",
    "plt.title('TB with Dynamic Forecast', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=10)\n",
    "plt.ylabel('Num. Deaths', fontsize=10)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the predicted and true values of our time series\n",
    "y_truth = series_data[start_date:]\n",
    "\n",
    "# Compute the errors\n",
    "rmse = calc_rmse(y_truth, y_forecasted)\n",
    "mape = calc_mape(y_truth, y_forecasted)\n",
    "print('The RMSE of our forecasts is: {}'.format(round(rmse, 3)))\n",
    "print('The MAPE of our forecasts is: {} %'.format(round(mape, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Producing and visualizing forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get forecast n steps ahead in future (1 year)\n",
    "pred_bj = model.get_forecast(steps=n_forecast)\n",
    "y_forecasted = np.array([max(round(p),0) for p in pred_bj.predicted_mean])\n",
    "\n",
    "# Get confidence intervals of forecasts\n",
    "pred_df = pd.DataFrame(y_forecasted, columns=['forecast'])\n",
    "pred_df = pred_df.set_index(pred_bj.predicted_mean.index)\n",
    "pred_ci = pred_bj.conf_int(alpha=1-ci_alpha)\n",
    "pred_df['ci_inf'] = pred_ci.iloc[:, 0]\n",
    "pred_df['ci_sup'] = pred_ci.iloc[:, 1]\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ARIMA results\n",
    "plt.figure(figsize=(18, 7), dpi=200)\n",
    "ax = dataset['value'].plot(label='Observed')\n",
    "pred_df.forecast.plot(ax=ax, label='Forecast', color='green', linestyle='dashed')\n",
    "ax.fill_between(pred_ci.index, pred_df.ci_inf, pred_df.ci_sup, color='k', alpha=.2)\n",
    "plt.ylim((0, max_y))\n",
    "plt.title('SARIMA Forecast', fontsize=14)\n",
    "plt.xlabel('Date', fontsize=10)\n",
    "plt.ylabel('Num. Deaths', fontsize=10)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ARIMA residual errors\n",
    "residuals = pd.DataFrame(model.resid)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(18, 5))\n",
    "residuals.plot(title=\"ARIMA Residuals\", ax=ax[0])\n",
    "residuals.plot(kind='kde', title='Density', ax=ax[1])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result\n",
    "- RMSE: 85.051\n",
    "- MAPE: 5.875 %\n",
    "- AIC: 252.261\n",
    "- BIC: 255.534\n",
    "- Elapsed Time: 4 min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Holt-Winters Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exponential smoothing** is a time series forecasting method for univariate data that can be extended to support data with a systematic trend or seasonal component.\n",
    "\n",
    "There are three types of exponential smoothing; they are:\n",
    "- Single Exponential Smoothing, or SES, for univariate data without trend or seasonality.\n",
    "- Double Exponential Smoothing for univariate data with support for trends.\n",
    "- Triple Exponential Smoothing, or **Holt-Winters** Exponential Smoothing, with support for both trends and seasonality.\n",
    "\n",
    "We will use the implementation of <a href=\"https://www.statsmodels.org/dev/generated/statsmodels.tsa.holtwinters.ExponentialSmoothing.html\" target=\"_blank\">Holt-Winters Exponential Smoothing</a> provided by the statsmodels library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Select best parameters for Holt-Winters model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model has hyperparameters that control the nature of the exponential performed for the series, trend, and seasonality, specifically:\n",
    "- **smoothing_level** (alpha): the smoothing coefficient for the level.\n",
    "- **smoothing_slope** (beta): the smoothing coefficient for the trend.\n",
    "- **smoothing_seasonal** (gamma): the smoothing coefficient for the seasonal component.\n",
    "- **damping_slope** (phi): the coefficient for the damped trend.\n",
    "\n",
    "There are other hyperparameters that the model will not automatically tune that you may want to specify; they are:\n",
    "- **trend**: The type of trend component, as either “add” for additive or “mul” for multiplicative. Modeling the trend can be disabled by setting it to None.\n",
    "- **damped**: Whether or not the trend component should be damped, either True or False.\n",
    "- **seasonal**: The type of seasonal component, as either “add” for additive or “mul” for multiplicative. Modeling the seasonal component can be disabled by setting it to None.\n",
    "- **seasonal_periods**: The number of time steps in a seasonal period, e.g. 12 for 12 months in a yearly seasonal structure.\n",
    "- **use_boxcox**: Whether or not to perform a power transform of the series (True/False) or specify the lambda for the transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of exponential smoothing configs to try\n",
    "def exp_smoothing_configs(seasonal=[None]):\n",
    "    \n",
    "    # Define config lists\n",
    "    t_params = ['add', 'mul', None]\n",
    "    d_params = [True, False]\n",
    "    s_params = ['add', 'mul', None]\n",
    "    p_params = seasonal\n",
    "    b_params = [True, False]\n",
    "    r_params = [True, False]\n",
    "    \n",
    "    models = list(itertools.product(t_params, d_params, s_params, p_params, b_params, r_params))\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "    return data[:-n_test], data[-n_test:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-step Holt Winter’s Exponential Smoothing forecast\n",
    "def exp_smoothing_forecast(history, config):\n",
    "    t, d, s, p, b, r = config\n",
    "    \n",
    "    # define model\n",
    "    history = np.array(history)\n",
    "    model = ExponentialSmoothing(history, trend=t, damped=d, seasonal=s, seasonal_periods=p)\n",
    "    \n",
    "    # Fit model\n",
    "    model_fit = model.fit(optimized=True, use_boxcox=b, remove_bias=r)\n",
    "    \n",
    "    # Make one step forecast\n",
    "    yhat = model_fit.predict(len(history), len(history))\n",
    "    \n",
    "    return yhat[0]\n",
    "\n",
    "# Walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test, cfg):\n",
    "    predictions = list()\n",
    "    \n",
    "    # Split dataset\n",
    "    train, test = train_test_split(data, n_test)\n",
    "    \n",
    "    # Seed history with training dataset\n",
    "    history = [x for x in train]\n",
    "    \n",
    "    # Step over each time-step in the test set\n",
    "    for i in range(len(test)):\n",
    "        \n",
    "        # Fit model and make forecast for history\n",
    "        yhat = exp_smoothing_forecast(history, cfg)\n",
    "        \n",
    "        # Store forecast in list of predictions\n",
    "        predictions.append(yhat)\n",
    "        \n",
    "        # Add actual observation to history for the next loop\n",
    "        history.append(test[i])\n",
    "    \n",
    "    # Round predictions\n",
    "    predictions = np.array([round(p) for p in predictions])\n",
    "    \n",
    "    # Estimate prediction error\n",
    "    rmse = calc_rmse(test, predictions)\n",
    "    mape = calc_mape(test, predictions)\n",
    "    \n",
    "    return rmse, mape\n",
    "\n",
    "# Score a model, return None on failure\n",
    "def score_model(data, n_test, cfg, debug=False):\n",
    "    rmse, mape = None, None\n",
    "    \n",
    "    # Convert config to a key\n",
    "    key = str(cfg)\n",
    "    \n",
    "    # Show all warnings and fail on exception if debugging\n",
    "    if debug:\n",
    "        rmse, mape = walk_forward_validation(data, n_test, cfg)\n",
    "        \n",
    "        # Check for an interesting result\n",
    "        if rmse is not None or mape is not None:\n",
    "            print(' > Model %s, RMSE %.3f, MAPE %.3f' % (key, rmse, mape))\n",
    "    else:\n",
    "        # One failure during model validation suggests an unstable config\n",
    "        try:\n",
    "            # Never show warnings when grid searching, too noisy\n",
    "            with catch_warnings():\n",
    "                filterwarnings(\"ignore\")\n",
    "                rmse, mape = walk_forward_validation(data, n_test, cfg)\n",
    "        except:\n",
    "            rmse = None\n",
    "            mape = None\n",
    "    \n",
    "    return (key, rmse, mape)\n",
    "\n",
    "# Run grid search configs\n",
    "def hw_grid_search(data, param_list, n_test, parallel=True):\n",
    "    scores = None\n",
    "    \n",
    "    if parallel:\n",
    "        # Execute configs in parallel\n",
    "        executor = Parallel(n_jobs=cpu_count(), backend='multiprocessing')\n",
    "        tasks = (delayed(score_model)(data, n_test, cfg) for cfg in param_list)\n",
    "        scores = executor(tasks)\n",
    "    else:\n",
    "        scores = [score_model(data, n_test, cfg) for cfg in param_list]\n",
    "        \n",
    "    # Remove empty results\n",
    "    scores = [r for r in scores if r[1] is not None or r[2] is not None]\n",
    "    \n",
    "    # Sort configs by error, asc\n",
    "    scores.sort(key=lambda tup: tup[1])\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Holt-Winters fit\n",
    "if run_fit:\n",
    "    start_time = timeit.default_timer()\n",
    "    \n",
    "    # Calculation params\n",
    "    param_list = exp_smoothing_configs([0, 4, 13])\n",
    "    n_test = int(len(series_data.values) * perc_test)\n",
    "    parallel = False\n",
    "    \n",
    "    # Grid search\n",
    "    scores = hw_grid_search(series_data.values, param_list, n_test, parallel)\n",
    "    print('Done Holt-Winters method')\n",
    "    \n",
    "    # Elapsed time\n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    print('Elapsed time', elapsed, 's')\n",
    "    \n",
    "    # List top 10 configs\n",
    "    for cfg, rmse, mape in scores[:10]:\n",
    "        print(cfg, rmse, mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Create Holt-Winters model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting a Holt-Winters Time Series model\n",
    "history = series_data.values\n",
    "model = ExponentialSmoothing(history, trend='mul', damped=True, seasonal='add', seasonal_periods=13)\n",
    "model = model.fit(optimized=True, use_boxcox=False, remove_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Producing and visualizing forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get forecast n steps ahead in future (1 year)\n",
    "pred_hw = model.forecast(steps=n_forecast)\n",
    "y_forecasted = np.array([max(round(p),0) for p in pred_hw])\n",
    "\n",
    "# Get confidence intervals of forecasts\n",
    "pred_df = pd.DataFrame(y_forecasted, columns=['forecast'])\n",
    "pred_df = pred_df.set_index(pred_bj.predicted_mean.index)\n",
    "ci_beta = max(pred_hw) - max(pred_hw) * ci_alpha\n",
    "pred_df['ci_inf'] = pred_hw - ci_beta\n",
    "pred_df['ci_sup'] = pred_hw + ci_beta\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plt.figure(figsize=(18, 7), dpi=200)\n",
    "ax = dataset['value'].plot(label='Observed')\n",
    "pred_df.forecast.plot(ax=ax, label='Forecast', color='green', linestyle='dashed')\n",
    "ax.fill_between(pred_df.index, pred_df.ci_inf, pred_df.ci_sup, color='k', alpha=.2)\n",
    "plt.ylim((0, max_y))\n",
    "plt.title('Holt-Winters Forecast', fontsize = 14)\n",
    "plt.xlabel('Date', fontsize=10)\n",
    "plt.ylabel('Num. Deaths', fontsize=10)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Holt-Winters residual errors\n",
    "residuals = pd.DataFrame(model.resid)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(18, 5))\n",
    "residuals.plot(title=\"Holt-Winters Residuals\", ax=ax[0], legend=None)\n",
    "residuals.plot(kind='kde', title='Density', ax=ax[1], legend=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result\n",
    "- RMSE: 83.463\n",
    "- MAPE: 6.158 %\n",
    "- AIC: 344.480\n",
    "- BIC: 374.880\n",
    "- Elapsed Time: 5 min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set normalized data\n",
    "df = pd.DataFrame({\n",
    "    'group': ['BL', 'ARIMA','HW'],\n",
    "    'rmse': [0.833, 0.736, 0.716],\n",
    "    'mape': [0.833, 0.722, 0.735],\n",
    "    'aic': [0.833, 0.520, 0.705],\n",
    "    'bic': [0.833, 0.525, 0.762],\n",
    "    'time': [0.167, 0.515, 0.748]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 1: Create background\n",
    "# Number of variable\n",
    "categories = list(df)[1:]\n",
    "num_vars = len(categories)\n",
    "\n",
    "# What will be the angle of each axis in the plot? (we divide the plot / number of variable)\n",
    "angles = [n / float(num_vars) * 2 * pi for n in range(num_vars)]\n",
    "angles += angles[:1]\n",
    "\n",
    "# Initialise the spider plot\n",
    "plt.rcParams.update({'figure.figsize': (12, 10)})\n",
    "ax = plt.subplot(111, polar=True)\n",
    "\n",
    "# If you want the first axis to be on top:\n",
    "ax.set_theta_offset(pi / 2)\n",
    "ax.set_theta_direction(-1)\n",
    "\n",
    "# Pentagon instead of circle\n",
    "gridlines = ax.yaxis.get_gridlines()\n",
    "for gl in gridlines:\n",
    "    gl.get_path()._interpolation_steps = num_vars\n",
    "\n",
    "# Draw one axe per variable + add labels labels yet\n",
    "plt.xticks(angles[:-1], categories)\n",
    "\n",
    "# Draw ylabels\n",
    "ax.set_rlabel_position(0)\n",
    "plt.yticks([0.2, 0.4, 0.6, 0.8, 1], [\"20\",\"40\",\"60\", \"80\", \"100\"], color=\"grey\", size=7)\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# PART 2: Add plots\n",
    "items = {\n",
    "    'Base Line': 'b',\n",
    "    'SARIMA': 'r',\n",
    "    'Holt-Winters': 'g',\n",
    "}\n",
    "\n",
    "# Show items\n",
    "ix = 0\n",
    "for k, v in items.items():\n",
    "    values = df.loc[ix].drop('group').values.flatten().tolist()\n",
    "    values += values[:1]\n",
    "    ax.plot(angles, values, linewidth=1, linestyle='solid', label=k)\n",
    "    ax.fill(angles, values, v, alpha=0.1)\n",
    "    ix += 1\n",
    "\n",
    "# Add legend\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "End of analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
